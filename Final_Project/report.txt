尝试过的算法:
在一开始，我们仅考虑根据分析单帧的关键点信息以实现对动作的分类，我们基于openpose得到的关键点，转换成各关节部件的旋转角，作为神经网络和SVM的输入，尝试训练一个分类器，但最终检测效果并不理想。因此，我们又考虑引入RNN，对每一帧动作仍提取关节的旋转角，取20帧作为输入序列的定长，利用LSTM实现对动作的分类，但是我们又面临数据量不足、variaty不足的问题，同时缺少计算资源在有限的时间内实现这样一个网络的训练。最后，我们决定回归到对openpose输出的人体关节点骨架进行分析，基于角度、相对位置等因素去设计识别算法。

对openpose输出的关键点，如何区分开每个人，并赋予ID：
对每一个human的所有检测到的关节点，取其中最小的x和y坐标，作为ROI区域的左上角，取最大的x和y坐标作为ROI的右下角，由此获得每一个human的ROI区域，并用非极大抑制进行过滤，再基于deepsort算法实现多人跟踪，每次对tracker更新后，遍历结果，计算track box和human neck之间的距离，取结果中最小的以实现对每个human的ID的匹配

打架检测:



