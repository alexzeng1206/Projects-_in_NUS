{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"0717_exercise_1_explore_mlps.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"xYUoynEMAotH","colab_type":"text"},"source":["# Exercise 1: Explore MLPs  \n","## Train the MLP models on Fashion-MNIST dataset.  \n","\n","In this tutorial, we'll build and train a multiple perceptron neural network to classify images of clothing, like sneakers and shirts. \n","This guide uses [tf.keras](https://www.tensorflow.org/beta/guide/keras/overview), a high-level API to build and train models in TensorFlow.\n","\n","\n","Before running any code, we do the following two steps:\n","1. Reset the runtime by going to **Runtime -> Reset all runtimes** in the menu above. \n","2. Select **GPU** by going to **Runtime -> Change runtime type -> Hardware accelerator** in the menu above. \n","\n","**Fashion-MNIST** is a dataset of Zalando's article images—consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. We intend Fashion-MNIST to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms. It shares the same image size and structure of training and testing splits.\n"]},{"cell_type":"markdown","metadata":{"id":"NSZnPtg2Bqrx","colab_type":"text"},"source":["## [Install and import dependencies]\n","\n","Since we need to use the latest tensorflow version, which is Tensorflow 2.0 beta. We need to install it. The default Tensorflow version in Colab is r1.14.0. \n","\n","\n","First, we will import some packages which will be used in our codes.\n","- `numpy`: for matrix computation \n","- `matplotlib.pyplot`: for graph plotting and display\n","- `tensorflow`: the main deep learning toolbox\n","-  `keras.datasets`: an API providing several datasets for common use. "]},{"cell_type":"code","metadata":{"id":"rbAaVhGNAmzX","colab_type":"code","colab":{}},"source":[" ## Install tensorflow 2.0.0 beta version (GPU VERSION)\n"," !pip install tensorflow-gpu==2.0.0-beta1 "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uFosACU2gHdt","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"ttf0d6W9AoSQ","colab_type":"code","colab":{}},"source":["from __future__ import absolute_import, division, print_function, unicode_literals\n","\n","\n","# Import TensorFlow and Fashion-MNIST Datasets\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","# Helper libraries\n","import numpy as np\n","import matplotlib.pyplot as plt\n","print(tf.__version__)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZfgK9uCSzAln","colab_type":"code","colab":{}},"source":["# To ignore some warning message\n","import logging\n","logger = tf.get_logger()\n","logger.setLevel(logging.ERROR)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AI0o4v-XE0fs","colab_type":"text"},"source":["## [Data Loading]  \n","\n","**Fashion MNIST** has the same data structure as the regular **MNIST** dataset, but it's a slightly more challenging. Both datasets are relatively small and are used to verify that an algorithm works as expected. They're good starting points to test and debug code. \n","\n","We will use 60,000 images to train the network and 10,000 images to evaluate how accurately the network learned to classify images. You can access the Fashion MNIST directly from TensorFlow, using the [Datasets](https://www.tensorflow.org/datasets) API:"]},{"cell_type":"code","metadata":{"id":"IH3695kMHLJs","colab_type":"code","colab":{}},"source":["# load dataset\n","(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n","\n","# count the number of unique train labels\n","unique, counts = np.unique(y_train, return_counts=True)\n","print(\"Train labels: \", dict(zip(unique, counts)))\n","\n","#count the number of unique test labels\n","unique, counts = np.unique(y_test, return_counts=True)\n","print(\"Test labels: \", dict(zip(unique, counts)))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"udNSgLnKYloQ","colab_type":"text"},"source":["The images are 28 $\\times$ 28 arrays, with pixel values in the range `[0, 255]`. The *labels* are an array of integers, in the range `[0, 9]`. These correspond to the *class* of clothing the image represents:  \n","<table>\n","  <tr>\n","    <th>Label</th>\n","    <th>Class</th> \n","  </tr>\n","  <tr>\n","    <td>0</td>\n","    <td>T-shirt/top</td> \n","  </tr>\n","  <tr>\n","    <td>1</td>\n","    <td>Trouser</td> \n","  </tr>\n","    <tr>\n","    <td>2</td>\n","    <td>Pullover</td> \n","  </tr>\n","    <tr>\n","    <td>3</td>\n","    <td>Dress</td> \n","  </tr>\n","    <tr>\n","    <td>4</td>\n","    <td>Coat</td> \n","  </tr>\n","    <tr>\n","    <td>5</td>\n","    <td>Sandal</td> \n","  </tr>\n","    <tr>\n","    <td>6</td>\n","    <td>Shirt</td> \n","  </tr>\n","    <tr>\n","    <td>7</td>\n","    <td>Sneaker</td> \n","  </tr>\n","    <tr>\n","    <td>8</td>\n","    <td>Bag</td> \n","  </tr>\n","    <tr>\n","    <td>9</td>\n","    <td>Ankle boot</td> \n","  </tr>\n","</table>\n","\n","Each image is mapped to a single label. Since the *class names* are not included with the dataset, store them here to use later when plotting the images:\n"]},{"cell_type":"code","metadata":{"id":"SSIN2VWiYhJ3","colab_type":"code","colab":{}},"source":["class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n","               'Sandal',      'Shirt',   'Sneaker',  'Bag',   'Ankle boot']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ovR3Ma6dIrHO","colab_type":"code","colab":{}},"source":["# sample 25 mnist digits from train dataset\n","indexes = np.random.randint(0, x_train.shape[0], size=25)\n","images = x_train[indexes]\n","labels = y_train[indexes]\n","\n","# plot the 25 mnist digits\n","plt.figure(figsize=(10,10))\n","for i in range(len(indexes)):\n","  plt.subplot(5, 5, i + 1)\n","  image = images[i]\n","  label = labels[i]\n","  plt.imshow(image, cmap='gray')\n","  plt.xlabel(class_names[label])\n","  plt.xticks([])\n","  plt.yticks([])\n","  \n","plt.show()\n","plt.savefig(\"fashion_mnist-samples.png\")\n","plt.close('all')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RF412fHZbFeA","colab_type":"text"},"source":["### Data Preparation  \n","\n","The value of each pixel in the image data is an integer in the range `[0,255]`. For the model to work properly, these values need to be normalized to the range `[0,1]`. "]},{"cell_type":"code","metadata":{"id":"yMWJm5wtbPcX","colab_type":"code","colab":{}},"source":["# image dimensions (assumed square)\n","image_size = x_train.shape[1]\n","input_size = image_size * image_size\n","# resize and normalize\n","\n","x_train = np.reshape(x_train, [-1, input_size])\n","x_train = x_train.astype('float32')/255.0\n","x_test = np.reshape(x_test, [-1, input_size])\n","x_test = x_test.astype('float32')/255.0"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eTTICa7RZpxw","colab_type":"text"},"source":["##[Construct the Model]  \n","Building the neural network requires configuring the layers of the model, then compiling the model.  \n","We build a MLP model with 2 hidden layers. activation function -- 'relu'"]},{"cell_type":"code","metadata":{"id":"xk0WJSVLJX8p","colab_type":"code","colab":{}},"source":["# import tf.keras api for build the model architecture\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten\n","from tensorflow.keras.utils import to_categorical, plot_model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"J7YdQOybZkKg","colab_type":"code","colab":{}},"source":["# compute the number of labels\n","num_labels = len(np.unique(y_train))\n","# Define network parameters\n","batch_size = 128\n","hidden_units = 256\n","dropout = 0.4"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jaHx5YjoarOB","colab_type":"code","cellView":"code","colab":{}},"source":["# model is a 3-layer MLP with ReLU and dropout after each layer\n","  model = Sequential()\n","  model.add(Dense(256, activation='relu',input_shape=(784,)))\n","  model.add(Dropout(0.4))\n","  model.add(Dense(256, activation='relu'))\n","  model.add(Dropout(0.4))\n","  model.add(Dense(10, activation='softmax'))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JvnNZOJPpHon","colab_type":"code","colab":{}},"source":["model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VYKJIQDppQhD","colab_type":"text"},"source":["### Compile the model\n","\n","Before the model is ready for training, it needs a few more settings. These are added during the model's *compile* step:\n","\n","\n","* *Loss function* — An algorithm for measuring how far the model's outputs are from the desired output. The goal of training is this measures loss.\n","* *Optimizer* —An algorithm for adjusting the inner parameters of the model in order to minimize loss.\n","* *Metrics* —Used to monitor the training and testing steps. The following example uses *accuracy*, the fraction of the images that are correctly classified."]},{"cell_type":"code","metadata":{"id":"WNKyd_YhpQss","colab_type":"code","colab":{}},"source":["model.compile(optimizer='adam', \n","              loss='sparse_categorical_crossentropy',\n","              metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3Fia0WHSsOVt","colab_type":"text"},"source":["##[Train the Model]  \n"]},{"cell_type":"code","metadata":{"id":"mAi2wmsctg6N","colab_type":"code","colab":{}},"source":["EPOCHS = 50\n","history = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=EPOCHS, batch_size=batch_size)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2t23eRWZvNw4","colab_type":"code","colab":{}},"source":["loss, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n","print(\"\\nTest accuracy: %.1f%%\" % (100.0 * acc))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"20RxPoYSXcGu","colab_type":"text"},"source":["### history object for visualization  \n","\n","\n","The `fit` method returns a history object. We can use this object to plot how the loss of our model goes down after each training epoch. A high loss means that the Fahrenheit degrees the model predicts is far from the corresponding value in `fahrenheit_a`. \n","\n","We'll use [Matplotlib](https://matplotlib.org/) to visualize this (you could use another tool). As you can see, our model improves very quickly at first, and then has a steady, slow improvement towards the end."]},{"cell_type":"code","metadata":{"id":"r3udBW3_RBM6","colab_type":"code","colab":{}},"source":["plt.xlabel('Epoch Number')\n","plt.ylabel(\"Loss Magnitude\")\n","plt.plot(history.history['loss'], label='Training Loss')\n","plt.plot(history.history['val_loss'], label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.title('Training and Validation Loss')\n","# plt.savefig('./loss.png')"],"execution_count":0,"outputs":[]}]}